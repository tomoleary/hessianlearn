<!-- # hessianlearn -->


<!-- 			Hessian based stochastic optimization in tensorflow and keras -->

	      ___          ___          ___          ___                     ___          ___     
	     /__/\        /  /\        /  /\        /  /\       ___         /  /\        /__/\    
	     \  \:\      /  /:/_      /  /:/_      /  /:/_     /  /\       /  /::\       \  \:\   
	      \__\:\    /  /:/ /\    /  /:/ /\    /  /:/ /\   /  /:/      /  /:/\:\       \  \:\  
	  ___ /  /::\  /  /:/ /:/_  /  /:/ /::\  /  /:/ /::\ /__/::\     /  /:/~/::\  _____\__\:\ 
	 /__/\  /:/\:\/__/:/ /:/ /\/__/:/ /:/\:\/__/:/ /:/\:\\__\/\:\__ /__/:/ /:/\:\/__/::::::::\
	 \  \:\/:/__\/\  \:\/:/ /:/\  \:\/:/~/:/\  \:\/:/~/:/   \  \:\/\\  \:\/:/__\/\  \:\~~\~~\/
	  \  \::/      \  \::/ /:/  \  \::/ /:/  \  \::/ /:/     \__\::/ \  \::/      \  \:\  ~~~ 
	   \  \:\       \  \:\/:/    \__\/ /:/    \__\/ /:/      /__/:/   \  \:\       \  \:\     
	    \  \:\       \  \::/       /__/:/       /__/:/       \__\/     \  \:\       \  \:\    
	     \__\/        \__\/        \__\/        \__\/                   \__\/        \__\/    


			                   ___          ___          ___          ___     
			                  /  /\        /  /\        /  /\        /__/\    
			                 /  /:/_      /  /::\      /  /::\       \  \:\   
			  ___     ___   /  /:/ /\    /  /:/\:\    /  /:/\:\       \  \:\  
			 /__/\   /  /\ /  /:/ /:/_  /  /:/~/::\  /  /:/~/:/   _____\__\:\ 
			 \  \:\ /  /://__/:/ /:/ /\/__/:/ /:/\:\/__/:/ /:/___/__/::::::::\
			  \  \:\  /:/ \  \:\/:/ /:/\  \:\/:/__\/\  \:\/:::::/\  \:\~~\~~\/
			   \  \:\/:/   \  \::/ /:/  \  \::/      \  \::/~~~~  \  \:\  ~~~ 
			    \  \::/     \  \:\/:/    \  \:\       \  \:\       \  \:\     
			     \__\/       \  \::/      \  \:\       \  \:\       \  \:\    
			                  \__\/        \__\/        \__\/        \__\/    




					https://arxiv.org/abs/1905.06738
					https://arxiv.org/abs/2002.02881


[![Build Status](https://travis-ci.com/tomoleary/hessianlearn.svg?branch=master)](https://travis-ci.com/tomoleary/hessianlearn)
[![License](https://https://img.shields.io/github/license/tomoleary/hessianlearn)](./LICENSE)
[![Top language](https://img.shields.io/github/languages/top/tomoleary/hessianlearn)](https://www.python.org)
![Code size](https://img.shields.io/github/languages/code-size/tomoleary/hessianlearn)
[![Issues](https://img.shields.io/github/issues/tomoleary/hessianlearn)](https://github.com/tomoleary/hessianlearn/issues)
[![Latest commit](https://img.shields.io/github/last-commit/tomoleary/hessianlearn)](https://github.com/tomoleary/hessianlearn/commits/master)

# Hessian based stochastic optimization in TensorFlow and keras



# References

These papers motivate and use the hessianlearn library for stochastic nonconvex optimization

- \[1\] O'Leary-Roseberry, T., Alger, N., Ghattas O.,
[**Inexact Newton Methods for Stochastic Nonconvex Optimization with Applications to Neural Network Training**](https://arxiv.org/abs/1905.06738).
arXiv:1905.06738.
([Download](https://arxiv.org/pdf/1905.06738.pdf))<details><summary>BibTeX</summary><pre>
@article{o2019inexact,
  title={Inexact Newton methods for stochastic nonconvex optimization with applications to neural network training},
  author={O'Leary-Roseberry, Thomas and Alger, Nick and Ghattas, Omar},
  journal={arXiv preprint arXiv:1905.06738},
  year={2019}
}
}</pre></details>


